# Image-Captioning-Model
In this model, we used the Flikr-8K dataset.<br>
The image features we extracted using ResNet. Then the text was pre processed and converted to indexes. We then train the image features along with the text to get the desired numerical index which is then again converted into alphabets.
